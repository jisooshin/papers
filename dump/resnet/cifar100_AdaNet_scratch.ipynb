{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T02:57:15.969818Z",
     "start_time": "2019-10-24T02:57:14.396980Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T02:57:16.214039Z",
     "start_time": "2019-10-24T02:57:16.210943Z"
    }
   },
   "outputs": [],
   "source": [
    "base_path = os.environ['HOME'] + '/cifar100/AdaNet'\n",
    "if os.path.isdir(base_path):\n",
    "  pass\n",
    "else:\n",
    "  os.mkdir(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T02:57:17.795242Z",
     "start_time": "2019-10-24T02:57:16.779846Z"
    }
   },
   "outputs": [],
   "source": [
    "data = tf.keras.datasets.cifar100.load_data()\n",
    "\n",
    "train = data[0]\n",
    "test = data[1]\n",
    "\n",
    "train_image, train_label = train[0].astype(np.float32), train[1]\n",
    "test_image, test_label= test[0].astype(np.float32), test[1]\n",
    "\n",
    "train_label = np.reshape(train_label, newshape=[-1])\n",
    "test_label = np.reshape(test_label, newshape=[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T02:57:19.959806Z",
     "start_time": "2019-10-24T02:57:19.033565Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generate Dataset obj   \n",
    "dataset_obj = tf.data.Dataset.from_tensors(\n",
    "    {'image': train_image, 'label': train_label})\n",
    "dataset_obj = dataset_obj.shuffle(50000)\n",
    "dataset_obj = dataset_obj.unbatch()\n",
    "\n",
    "# split train-validation dataset\n",
    "train_dataset = dataset_obj.take(40000)\n",
    "val_dataset = dataset_obj.skip(40000).take(10000)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensors(\n",
    "  {'image': test_image, 'label': test_label})\n",
    "test_dataset = test_dataset.shuffle(10000).unbatch()\n",
    "\n",
    "def _preprocessing(dataset, train_mode):\n",
    "  \"\"\"\n",
    "  While train steps, image will be padded random crop and filped(horizontaly)\n",
    "  And entire steps, per-pixel mean subtracted will be required.\n",
    "  Args:\n",
    "    dataset: 'tf.data.Dataset'\n",
    "    train_mode: 'bool'\n",
    "  Returns:\n",
    "    'tf.data.Dataset'\n",
    "  \"\"\"\n",
    "  if train_mode:\n",
    "    image = dataset['image']\n",
    "    pad = tf.constant([[2, 2], [2, 2], [0, 0]])\n",
    "    image = tf.pad(\n",
    "      tensor=image, paddings=pad)\n",
    "    image = tf.image.random_crop(\n",
    "      value=image, size=[32, 32, 3])\n",
    "    image = tf.image.random_flip_left_right(image=image)\n",
    "  else:\n",
    "    image = dataset['image']\n",
    "    \n",
    "  image = tf.math.subtract(\n",
    "    x=image,\n",
    "    y=tf.reshape(\n",
    "      tf.math.reduce_mean(image, axis=2), shape=[32, 32, 1]))\n",
    "  label = dataset['label']\n",
    "  return (image, label)\n",
    "\n",
    "train_dataset = train_dataset.map(\n",
    "  lambda x: _preprocessing(x, train_mode=True))\n",
    "val_dataset = val_dataset.map(\n",
    "  lambda x: _preprocessing(x, train_mode=False))\n",
    "test_dataset = test_dataset.map(\n",
    "  lambda x: _preprocessing(x, train_mode=False))\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.repeat()\n",
    "val_dataset = val_dataset.repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T02:57:21.207071Z",
     "start_time": "2019-10-24T02:57:21.189023Z"
    }
   },
   "outputs": [],
   "source": [
    "# WEAK LEARNER \n",
    "def residual_block_tensor(x):\n",
    "  identity_x = x\n",
    "  identity_x = keras.layers.Conv2D(\n",
    "    filters=256, kernel_size=[1, 1], strides=1, padding='same')(identity_x)\n",
    "  identity_x = keras.layers.BatchNormalization()(identity_x)\n",
    "  identity_x = keras.layers.ReLU()(identity_x)\n",
    "  \n",
    "  x = keras.layers.Conv2D(\n",
    "    filters=64, kernel_size=[1, 1], strides=1, padding='same')(x)\n",
    "  x = keras.layers.BatchNormalization()(x)\n",
    "  x = keras.layers.ReLU()(x)\n",
    "\n",
    "  x = keras.layers.Conv2D(\n",
    "    filters=64, kernel_size=[3, 3], strides=1, padding='same')(x)\n",
    "  x = keras.layers.BatchNormalization()(x)\n",
    "  x = keras.layers.ReLU()(x)\n",
    "  \n",
    "  x = keras.layers.Conv2D(\n",
    "    filters=256, kernel_size=[1, 1], strides=1, padding='same')(x)\n",
    "  x = keras.layers.BatchNormalization()(x)\n",
    "  x = keras.layers.ReLU()(x)\n",
    "  \n",
    "  x = keras.layers.Add()([x, identity_x])\n",
    "  x = keras.layers.ReLU()(x)\n",
    "  return x\n",
    "\n",
    "\n",
    "# residual block custom layer\n",
    "class ResidualBlock(keras.layers.Layer):\n",
    "  def __init__(self, constraint, **kwargs):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "      constraint(int): Max constraint for variable. (upper lambda)\n",
    "    \"\"\"\n",
    "    super(ResidualBlock, self).__init__()\n",
    "    self.conv_idt = keras.layers.Conv2D(\n",
    "      filters=3, kernel_size=[1, 1],\n",
    "      strides=1, padding='same', name='ConvIdt',\n",
    "      kernel_constraint=keras.constraints.MaxNorm(constraint))\n",
    "    self.bn_idt = keras.layers.BatchNormalization()\n",
    "    self.relu_idt = keras.layers.ReLU()\n",
    "    \n",
    "    self.conv_1 = keras.layers.Conv2D(\n",
    "      filters=64, kernel_size=[1, 1],\n",
    "      strides=1, padding='same', name='Conv1',\n",
    "      kernel_constraint=keras.constraints.MaxNorm(constraint))\n",
    "    self.bn_1 = keras.layers.BatchNormalization()\n",
    "    self.relu_1 = keras.layers.ReLU()\n",
    "    \n",
    "    self.conv_2 = keras.layers.Conv2D(\n",
    "      filters=64, kernel_size=[1, 1],\n",
    "      strides=1, padding='same', name='Conv2',\n",
    "      kernel_constraint=keras.constraints.MaxNorm(constraint))\n",
    "    self.bn_2 = keras.layers.BatchNormalization()\n",
    "    self.relu_2 = keras.layers.ReLU()\n",
    "    \n",
    "    self.conv_3 = keras.layers.Conv2D(\n",
    "      filters=3, kernel_size=[1, 1],\n",
    "      strides=1, padding='same', name='Conv3',\n",
    "      kernel_constraint=keras.constraints.MaxNorm(constraint))\n",
    "    self.bn_3 = keras.layers.BatchNormalization()\n",
    "    self.relu_3 = keras.layers.ReLU()\n",
    "    \n",
    "    self.add_last = keras.layers.Add()\n",
    "    self.relu_last = keras.layers.ReLU()\n",
    "    \n",
    "  def call(self, inputs):\n",
    "    idt_x = self.conv_idt(inputs)\n",
    "    idt_x = self.bn_idt(idt_x)\n",
    "    idt_x = self.relu_idt(idt_x)\n",
    "    x = self.conv_1(inputs)\n",
    "    x = self.bn_1(x)\n",
    "    x = self.relu_1(x)\n",
    "    x = self.conv_2(x)\n",
    "    x = self.bn_2(x)\n",
    "    x = self.relu_2(x)\n",
    "    x = self.conv_3(x)\n",
    "    x = self.bn_3(x)\n",
    "    x = self.relu_3(x)\n",
    "    x = self.add_last([x, idt_x])\n",
    "    return self.relu_last(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T02:57:22.477311Z",
     "start_time": "2019-10-24T02:57:22.470413Z"
    }
   },
   "outputs": [],
   "source": [
    "class AdaNetLoss(keras.losses.Loss):\n",
    "  \n",
    "  def __init__(self, \n",
    "               weight, \n",
    "               num_outputs, \n",
    "               batch_size, \n",
    "               num_classes,\n",
    "               name='weighted_loss'):\n",
    "    super(AdaNetLoss, self).__init__()\n",
    "    self.weight = weight\n",
    "    self.num_outputs = num_outputs\n",
    "    self.batch_size = batch_size\n",
    "    self.num_classes = num_classes\n",
    "\n",
    "  def call(self, y_true, y_pred):\n",
    "    weighted_pred = tf.tensordot(\n",
    "      tf.reshape(self.weight, shape=[self.num_outputs, 1]),\n",
    "      tf.reshape(\n",
    "        y_pred, shape=[self.num_outputs, self.batch_size, self.num_classes]),\n",
    "      axes=[[0], [0]])\n",
    "    weighted_pred_mean = tf.math.multiply(\n",
    "      weighted_pred, 1/self.num_outputs)\n",
    "    \n",
    "    loss = tf.keras.losses.categorical_crossentropy(\n",
    "      y_true=y_true,\n",
    "      y_pred=weighted_pred_mean)\n",
    "    \n",
    "    loss_without_nan = tf.where(\n",
    "      tf.math.is_nan(loss), tf.zeros_like(loss), loss)\n",
    "    print(loss_without_nan)\n",
    "    print(tf.reduce_sum(loss_without_nan))\n",
    "    return tf.reduce_sum(loss_without_nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 만들어야 할것\n",
    "1. keras.Model object (모델에 Loss까지 정의 되어야 하는가..?)\n",
    "    * Args (\\__init__에 들어가는 것)\n",
    "        - base classifier 의 층 수 <U>이건 어떻게 처리할 것인가 for loop로 layer를 쌓는가?</U>\n",
    "        (그리고 각 층별로 logit이 나와야 층별로 나온 logit을 바탕으로 weighted loss를 구할 수 있으니깐..)\n",
    "        - for loop를 돌리면서 하도록 하고.. outputs에 대한 비어있는 list를 먼저 만들어서(층 수는 미리 파악하면 되니깐) 각 list의 element에 결과로 나온 logit을 할당해주면 되겠다\n",
    "    * Returns ( call 에 들어가는 것)\n",
    "        - Logit이 필요한데.. 각 층별 Logit이 필요 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "keras.Model subclassing이 과연 필요한가?\n",
    "- 각 층별로 logit이 나오고, 그 logit들을 바탕으로 weighted loss를 구해야함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T02:57:23.689600Z",
     "start_time": "2019-10-24T02:57:23.687221Z"
    }
   },
   "outputs": [],
   "source": [
    "# custom model 에서는\n",
    "# layer의 갯수를 입력으로 받고 \n",
    "# output으로는 weighted loss값을 빼낸다.\n",
    "# custom model 에서 loss를 넣어주자 (나중에 뽑아 쓸수 있도록)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-23T06:46:43.781728Z",
     "start_time": "2019-10-23T06:46:43.777069Z"
    }
   },
   "source": [
    "```python\n",
    "class AdaResNet(keras.Model):\n",
    "  def __init__(self,\n",
    "               num_layer,\n",
    "               name='adaresnet',\n",
    "               **kwargs):\n",
    "    super(AdaResNet, self).__init__(name=name, **kwargs)\n",
    "    self.num_layer = num_layer\n",
    "    \n",
    "  def call(self, inputs):\n",
    "    output_list = [\n",
    "      \"output_\" + str(x) for x in list(range(1, self.num_layer+1))]\n",
    "    x = inputs\n",
    "    for i in range(self.num_layer):\n",
    "      x = ResidualBlock(constraint=2)(x)\n",
    "      _output = keras.layers.GloablAveragePooing2D()(x)\n",
    "      _output = keras.layers.Dense(100, name=output_list[i])(_output)\n",
    "      output_list[i] = _output\n",
    "    \n",
    "    return output_list\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T02:57:24.943502Z",
     "start_time": "2019-10-24T02:57:24.941598Z"
    }
   },
   "outputs": [],
   "source": [
    "#train_data, label = next(iter(train_dataset.batch(100)))\n",
    "#oh_label = tf.one_hot(label, depth=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T02:57:27.170141Z",
     "start_time": "2019-10-24T02:57:26.164991Z"
    }
   },
   "outputs": [],
   "source": [
    "# AdaNet에서 layer를 쌓아가는 방식\n",
    "\n",
    "NUM_OF_LAYERS = 5\n",
    "\n",
    "inputs = keras.Input(shape=[32, 32, 3], name='img1')\n",
    "\n",
    "if NUM_OF_LAYERS==0:\n",
    "  x = inputs\n",
    "  _output = keras.layers.GlobalAveragePooling2D()(x)\n",
    "  _output = keras.layers.Dense(100, name=\"first_iter_output\")(_output)\n",
    "  output_list = [_output]\n",
    "else:\n",
    "  output_list = [\"output_\" + str(x) for x in list(range(1, NUM_OF_LAYERS+1))]\n",
    "  x = inputs\n",
    "  for i in range(NUM_OF_LAYERS):\n",
    "    x = ResidualBlock(constraint=2)(x)\n",
    "    _output = keras.layers.GlobalAveragePooling2D()(x)\n",
    "    _output = keras.layers.Dense(100, name=output_list[i])(_output)\n",
    "    output_list[i] = _output\n",
    "    \n",
    "model = keras.Model(inputs=inputs, outputs=output_list)\n",
    "\n",
    "# weighted loss값이 어떤지 봐야하니깐\n",
    "# pred, true를 비교해줘야겠지\n",
    "weight = tf.Variable(\n",
    "  tf.ones(shape=[NUM_OF_LAYERS], dtype=tf.float32),\n",
    "  trainable=True, name='Weight')\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## model.fit으로 학습시키자..\n",
    "\n",
    "adanetloss = AdaNetLoss(\n",
    "        weight=weight, \n",
    "        num_outputs=NUM_OF_LAYERS,\n",
    "        batch_size=100,\n",
    "        num_classes=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T02:57:36.992174Z",
     "start_time": "2019-10-24T02:57:28.487635Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of epoch 1\n",
      "tf.Tensor(\n",
      "[[16.118095   2.9371088 16.118095  16.118095  16.118095   3.9599874\n",
      "   2.8232362 16.118095   5.206488   2.9089415  3.1885839  0.\n",
      "   3.60108    3.7968016  3.962757   2.553859  16.118095   2.9172077\n",
      "   2.4682164  3.9466531  1.8105428 16.118095   7.756285  16.118095\n",
      "  16.118095   2.3850057 16.118095   2.1971176  2.7807946 16.118095\n",
      "  16.118095   4.230486   2.1174421  2.6368003 16.118095  16.118095\n",
      "  16.118095  16.118095  16.118095   2.2785923  2.0040264 16.118095\n",
      "   6.297841   2.1944757 16.118095   3.8360257 16.118095   2.696613\n",
      "  16.118095   1.9790372  4.980382  16.118095  16.118095   2.2347324\n",
      "   3.5366406 16.118095   2.068073   5.0817366 16.118095   2.2370431\n",
      "   2.2041352  2.9119291  3.2456284  3.9178157 16.118095  16.118095\n",
      "  16.118095  16.118095   2.974377   4.4356985  3.0627563 16.118095\n",
      "  16.118095  16.118095   2.3910856  4.1546845 16.118095  16.118095\n",
      "  16.118095   2.9117332  2.5411854 16.118095   4.9299655 16.118095\n",
      "   5.483402   2.4447718 16.118095  16.118095  16.118095   3.1884122\n",
      "  16.118095  16.118095  16.118095   3.0679061  2.6919737 16.118095\n",
      "   3.8699079  0.         4.49313    3.310824 ]], shape=(1, 100), dtype=float32)\n",
      "tf.Tensor(889.03815, shape=(), dtype=float32)\n",
      "step 0: loss= 889.0381469726562\n",
      "tf.Tensor(\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]], shape=(1, 100), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]], shape=(1, 100), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]], shape=(1, 100), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]], shape=(1, 100), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]], shape=(1, 100), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]], shape=(1, 100), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-e955ac44e56c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m       \u001b[0mexpected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m       \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m       \"\"\"\n\u001b[1;32m     16\u001b[0m       weighted_predicted = tf.tensordot(\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    890\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    706\u001b[0m     return self._run_internal_graph(\n\u001b[1;32m    707\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m         convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n\u001b[0m\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask, convert_kwargs_to_constants)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m           \u001b[0;31m# Compute outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m           \u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomputed_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m           \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    890\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-b27713300092>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    890\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    206\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'NCHW'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'NHWC'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mbias_add\u001b[0;34m(value, bias, data_format, name)\u001b[0m\n\u001b[1;32m   2716\u001b[0m       \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m       \u001b[0mbias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"bias\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2718\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_nn_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mbias_add\u001b[0;34m(value, bias, data_format, name)\u001b[0m\n\u001b[1;32m    740\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"BiasAdd\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_post_execution_callbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data_format\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 742\u001b[0;31m         data_format)\n\u001b[0m\u001b[1;32m    743\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "adanetloss = AdaNetLoss(\n",
    "        weight=weight, \n",
    "        num_outputs=NUM_OF_LAYERS,\n",
    "        batch_size=100,\n",
    "        num_classes=100)\n",
    "\n",
    "for epoch in range(3):\n",
    "  print('Start of epoch {}'.format(epoch+1))\n",
    "  \n",
    "  for step, x_batch_train in enumerate(train_dataset.batch(100)):\n",
    "    with tf.GradientTape() as tape:\n",
    "      \n",
    "      expected = tf.one_hot(x_batch_train[1], depth=100)\n",
    "      predicted = model(x_batch_train[0])\n",
    "      \"\"\"\n",
    "      weighted_predicted = tf.tensordot(\n",
    "        tf.reshape(weight, shape=[5, 1]),\n",
    "        tf.reshape(predicted, shape=[5, 100, 100]), axes=[[0], [0]])\n",
    "      \n",
    "      weighted_pred_mean = tf.math.multiply(\n",
    "        weighted_predicted, 1/len(weighted_predicted))\n",
    "      \n",
    "      #print(tf.math.reduce_mean(weighted_pred_mean, axis=0))\n",
    "      #print(expected)\n",
    "      \n",
    "      loss = tf.keras.losses.categorical_crossentropy(\n",
    "        y_true=expected,\n",
    "        y_pred=tf.math.reduce_mean(predicted, axis=0))\n",
    "\n",
    "      loss = loss_metric(loss)\n",
    "      \"\"\"\n",
    "      loss = adanetloss(expected, predicted)\n",
    "      #print(loss)\n",
    "      \n",
    "    train_list = model.trainable_weights\n",
    "    train_list.append(weight)\n",
    "    \n",
    "    grads = tape.gradient(loss, train_list)\n",
    "    #print(grads)\n",
    "    optimizer.apply_gradients(zip(grads, train_list))\n",
    "    \n",
    "    \n",
    "    if step % 100 == 0:\n",
    "      print(\"step {}: loss= {}\".format(step, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss 자체를 kears custom loss로 만들어보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected = tf.one_hot(x_batch_train[1], depth=100)\n",
    "predicted = model(x_batch_train[0])\n",
    "\n",
    "weighted_predicted = tf.tensordot(\n",
    "  tf.reshape(weight, shape=[5, 1]),\n",
    "  tf.reshape(predicted, shape=[5, 100, 100]), axes=[[0], [0]])\n",
    "\n",
    "weighted_pred_mean = tf.math.multiply(\n",
    "  weighted_predicted, 1/len(weighted_predicted))\n",
    "\n",
    "#print(tf.math.reduce_mean(weighted_pred_mean, axis=0))\n",
    "#print(expected)\n",
    "\n",
    "loss = tf.keras.losses.categorical_crossentropy(\n",
    "  y_true=expected,\n",
    "  y_pred=tf.math.reduce_mean(predicted, axis=0))\n",
    "\n",
    "loss = loss_metric(loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T02:11:06.743768Z",
     "start_time": "2019-10-24T02:11:06.739907Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-23T06:48:19.863900Z",
     "start_time": "2019-10-23T06:48:19.858247Z"
    }
   },
   "outputs": [],
   "source": [
    "## trainable_weights를 구하려는 것은 Rademacher Complexity의 \n",
    "## upper bound 를 계산하기 위해 weight 와 unit size를 구하는 것이 필요하다\n",
    "\n",
    "# keras.Model subclassing 해서 하도록 하자.. 해당 subclassing된 Model object에는 \n",
    "# weight * outputs_list까지 포함하게 한다. \n",
    "\n",
    "weights_list = model.trainable_weights\n",
    "weights_list = [x for x in weights_list if 'Conv' in x.name]\n",
    "weights_list = [x for x in weights_list if 'kernel:0' in x.name]\n",
    "normed_weights_list = [tf.norm(tensor=x, ord=2) for x in weights_list]\n",
    "\n",
    "output_units = 32*32*3*3 # 이것이 1층 layer hypothesis의 N을 나타냄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-23T06:48:20.947341Z",
     "start_time": "2019-10-23T06:48:20.941251Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 여기서 계산한 weights_list의 각 weights별 l2_norm을 \n",
    "np.prod(normed_weights_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-23T08:42:54.992649Z",
     "start_time": "2019-10-23T08:42:54.852078Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbIAAAFgCAYAAADehfw4AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAABsqADAAQAAAABAAABYAAAAACpmp2sAABAAElEQVR4Ae2dB7gURfb2DxkTSQQxISKYERUDuiooKigGRECSYFhzXgNrZF0VXVkXEyioa1xU1FXRNWNYRcQErDkrmAMmRCXUd97zt/rryT0zPTN37rzneeZOd3XFX3XXqTp1em4DpyIUEiABEiABEqhSAg2rtN6sNgmQAAmQAAkYASoy3ggkQAIkQAJVTYCKrKq7j5UnARIgARKgIuM9QAIkQAIkUNUEGld17Vn5shMYP368zJ49u+zlssDaInDFFVdI+/bta6vRbG3BBLgiKxhdbSacOXOmzJo1qzYbz1aXnMDChQtl2rRpsmjRopKXxQLqDwGuyOpPX5atJTvssINMnTq1bOWxoNoh8PLLL8tWW21VOw1mS2MhwBVZLBiZCQmQAAmQQKUIUJFVijzLJQESIAESiIUAFVksGJkJCZAACZBApQhQkVWKPMslARIgARKIhQAVWSwYmQkJkAAJkEClCFCRVYo8yyUBEiABEoiFABVZLBiZCQmQAAmQQKUIUJFVijzLJQESIAESiIUAFVksGJkJCZAACZBApQhQkVWKPMslARIgARKIhQAVWSwYmQkJkAAJkEClCFCRVYo8yyUBEiABEoiFABVZLBiZCQmQAAmQQKUIUJFVijzLJQESIAESiIUAFVksGJkJCZAACZBApQjw/5FVinyNlOuck1133VVWWGEFeeCBB8re6k8++UQuuugiOfnkk6VTp055lf/qq6/KlClTUtIMHDhQdtppp5Twcgecc8458v333ycU27t3b9lvv/0SwnhCAvWdABVZfe/hCrdv+fLl8r///U+aNm0qOG7YsDxGgC+++ELGjRsn11xzjfzyyy9y+OGH501ik002kVNOOUX69esnr732mqy22mryzDPPyPrrr593XnElwMSgQYMGlh3adNpppwX/5PT222+X3XffPa6imA8JVA2B8owqVYODFY2bQKNGjeSdd96RN954o2xKDG349NNP5aijjpLtttuu4CZBYay99tqyxx57WB477rijdO3ataztCFceEwGsbpctW2bBa621lgwZMsSO27dvL4MHD5YVV1wxnITHJFATBLgiq4lurmwjW7VqVfYKbLHFFlYmFFGx0rJlS8vCfxebX6HpzzjjDHniiScEqzIvq6yyih2utNJKPojfJFBzBLgiq7kuL2+DFy9eLHfeeacMGDAgWEl8++23MnHiRLngggtk/vz5Zh7bZ5995JZbbrE47733nvz1r3+V/v37m3kwPHCj9s8//7wMHTpUevbsKQcffLBMmjRJZs6cKfPmzcurcUiz2267ydNPP51XOkT+7rvvrL7777+/teGKK64ws94hhxwin3/+ueX3ww8/WJx9991X0KaxY8fKDjvsIIMGDQrqijoMHz5cDjzwQLnrrrssHfb0cI4PrkOgxC6++GI7PvTQQ+XMM8+043z/IL9TTz1Vdt55Z9lrr71k+vTplgXYYQXrP9dff72Fv//++3LMMcdY+OOPPx4Ud88998jo0aPN7Iq6hPfqPvroI+u/Sy65RB5++GHp27evXHbZZUFaHpBA7AR0kKCQQGQCqpCcDrCR4n/55ZfuoIMOco0bN8YSwi1ZssSpidFtv/32dq6rJde9e3d30kkn2TfiDBs2zG244YZO93/cqquuavGuuuqqoDzdo7L8brvtNrdw4cIgLzWzWVlBxN8PRo4caXnoQJ18yZ1++ul27YQTTki5Fg74y1/+YvFUaQbBqoTdyiuvbOGorzqABHVRBWzxjj/+eNe8eXOLo44mTpWvUycRO9cVlFMlYfEuvfRSC1NFZ+dqQrT2g8d1111nYbNmzXIbbLCBxdNVmcM5RJWLha233np2nu0P2Okepbvhhhvcr7/+6lRBOTX9urfeesuSoU0oc+utt07I5uyzz3a69+aWLl1q4WeddZZTReiQnzrDuCZNmljdfv75Z6sP+hX5gAvqheubb755Qp6ZTl566SVLq4o/UxSGk0AKAZgpKCQQmUA+isxnus0229jgBEUG0ZWKnWNw/+abbyzs3XfftbDOnTs7XbFZ2AcffGBhYQUCJYHB1w+q9957r8WB4ksn2RQZysZADIWbTdIpMsQfMWKElQ3F4KVdu3auRYsW/tT16tXL4ujKJAjTVZuFHXHEERb20EMP2blXZAjUFauFeUWGsB49ejjdt8NhIPkoMigkKBgoC8j9999v57oStvPffvvNYUKAiYeuqiwMf3Tl69Tj1M5feeUV4//xxx8H13UP0fJRxxoLg6JFOWussYbTFbnTVbd9ggRZDqjIssDhpYwEaFrUJ45SWgLNmjVLKAD7OnCkWHPNNaVNmzZ2TRWY6ABqzhWtW7e2sHXXXVd0RSMwVXn56quvAvMjwrwzB8yV+QrKPuyww8wbMd+0iI9XCiC68rBv/Nl4440FJkVd8ViY37vSlWcQR1c0djxnzpwgLOqB91iMGj8cD+W+8MILsuWWW5p59uqrr7bLMO9CdOUkJ554ougkQS6//HILg0kU/L3Dizf/wlSsitU+uI7+8+ZFVWCWFmnQf3BKwYdCAqUiQEVWKrLMN28CyQoPGUC56UouyKtPnz52rCsx+4Y3JAT7MHVB4KWZSzp27Giej9hny1eKUWR4BQJlqulQrr32WtvfSi4fLv1wzsH7c1DIt956q+iqVny71AwpuuKUF198MfigD3RFbXtvyM+/YuHTJJfBcxKImwAVWdxEmV9JCcDpAasBfMMxASsIvEsFJ4tqkbffftveqevSpUveVS5EkT355JPmkAKnGyh8rEKhqMIrSV8RrJbBFUps8uTJpsjg1OEF7v24BoWWLGoKTg7iOQmUhQAVWVkws5AoBNQAnjMavCB1b0vuvvtuOfbYY+XZZ581b75CBngUhkE5l/h6+e9c8XNdhws9BF6DEKw6Id40h2OY9yB4d8wL2oh3yPw1hOeqE1jhXTMoIHg9Ir1/92zRokWWdXIe6qQiWB1jsgDza1jheRMpPBXD6eANqc4zvqr8JoGyEqAiKyvu2izMKwt1EDAA+NUNDILhgRsKSr3ebOXgKWGgRbh6J/og+6UNuIrPnTvXlNi0adPkwQcfNOUWRAod+DIxoCcLfvUDZrQLL7ww+VLC+WeffWbn/ttf9G724Xb4/bzk8u677z5Lhjapc4gpB7jRQ/AaAVZCMOPB7R2vE+D1A4g6ZAR7hNh7Ajd1ALF4r7/+uv3iCOKBMfhBEAfnjz32mOAnq/DTXOoBGihM7JVhdTZmzBiLP3v2bPGmWgSsvvrqMmrUKDPp4vWGsMD0iLriVQH8igj22Y4++mhRb1P5xz/+YVGxjwmB6z6FBMpCQG96CglEJpCP16IO6uaWrisJ82JTxwynKymn+1x2DldweBvqzz8Frut60zuUoYO003e8LB7CdGB1cO/WgTMIQ7j/qEJyTz31VNCO5557zvKBhyPi6M9NOf1twuA6DtShwa6FvQXDEfS3Fi0P3VuyeGiH/lyV0/fOnK5unDp7WDhcy/XdtsBlHuXBW/Hrr792uuqyON26dXPw3oRXoP5CiFMlGC7KqTJ1umoyj0Gk0T0spz+J5Y488kin+1EWVxWdeS2iHvrbkU5NhE5f0rb8USa8DeHWD66eC77PPfdcS6/vjDn9BRBzhwdbeAiqQ421A673YdGVroXrnlo42I519WUeib4M3fNzM2bMsGuqsM3tHtfA/oADDsjpFRougF6LYRo8jkrAfHn1pqOQQCQCeAEYZqepU6dGih93JH3nzMrHvg1m/liF/PTTT7ZKwW8h3njjjXkVqcpG2rZtm1eafCLjpW78WDJWc6grfh0Eq6N08uOPP5rZEF6bMB/qQ2yehOG4qC+cKby3Z/halGM4zuDjf8oK5eDce2D6PMaPH28vbd90000+KOEbdYNHoypV0XfFgt9/TIhUwMnLL78sW221leWNfCkkEIUAf6IqCiXGqRMEYHKbMGGCKTAon/DeDQb/Rx55JO96llKJhSsD5ZNrYIbJzovfN/Pn/rvY+sLFHh8vKMeXBeUEwY8s60voArNtJoECq+SPJ2eqF8NrkwAVWW32e1W2GgMsBPs0+FclcGPHPgx+surNN9+s2CoxG0y/V4Z/J6MvS2eLWtFreO9to402sr017Btuttlm9o5YRSvFwkkgIgE6e0QExWiVJwCnAvwPLvyyPdzt8cItXtzVn24y812HDh0qX8nfawDvQJg/8b4VBC7v+Zo9f8+qLF94xwwvLUPxYtUHRxgKCVQLAe6RVUtP1ZF6VnqPzGPA6gx7dTBx1VVJfuEZv3KBT10WeFX6XyOpRD25R1YJ6tVfJk2L1d+HNdmCuq4Q0Ckw0VWbVFKJVRsr1rfuEKBpse70BWtCAiRAAiRQAAEqsgKgMQkJkAAJkEDdIUBFVnf6gjUhARIgARIogAAVWQHQmIQESIAESKDuEKAiqzt9wZqQAAmQAAkUQICKrABoTEICJEACJFB3CFCR1Z2+YE1IgARIgAQKIEBFVgA0JiEBEiABEqg7BKjI6k5fsCYkQAIkQAIFEKAiKwAak5AACZAACdQdAlRkdacvWBMSIAESIIECCPC3FguAVutJ9L8Hy+DBg2sdA9tfAgILFy4sQa7Msr4ToCKr7z0cc/u233774B8xxpx1vcxuwYIFMn/+fOnZs2e9bF/cjcI/SB00aFBFf4E/7jYxv9IT4L9xKT1jllDDBPAfrcePHy9QaBQSIIHSEOAeWWm4MlcSIAESIIEyEaAiKxNoFkMCJEACJFAaAlRkpeHKXEmABEiABMpEgIqsTKBZDAmQAAmQQGkIUJGVhitzJQESIAESKBMBKrIygWYxJEACJEACpSFARVYarsyVBEiABEigTASoyMoEmsWQAAmQAAmUhgAVWWm4MlcSIAESIIEyEaAiKxNoFkMCJEACJFAaAlRkpeHKXEmABEiABMpEgIqsTKBZDAmQAAmQQGkIUJGVhitzJQESIAESKBMBKrIygWYxJEACJEACpSFARVYarsyVBEiABEigTASoyMoEmsWQAAmQAAmUhgAVWWm4MlcSIAESIIEyEaAiKxNoFkMCJEACJFAaAlRkpeHKXEmABEiABMpEgIqsTKBZDAmQAAmQQGkIUJGVhitzJQESIAESKBMBKrIygWYxJEACJEACpSFARVYarsyVBEiABEigTASoyMoEmsWQAAmQAAmUhgAVWWm4MlcSIAESIIEyEaAiKxNoFkMCJEACJFAaAlRkpeHKXEmABEiABMpEgIqsTKBZDAmQAAmQQGkIUJGVhitzJQESIAESKBMBKrIygWYxJEACJEACpSFARVYarsyVBEiABEigTASoyMoEmsWQAAmQAAmUhgAVWWm4MlcSIAESIIEyEWhcpnJYDAnUewLz5s2TMWPGiHMuaOv8+fPlhx9+kH79+gVhONh2221l7NixCWE8IQESKIxAA33o/v9TV1geTEUCJKAEfvvtN1l11VXlp59+yslj0qRJcuSRR+aMxwgkQAK5CdC0mJsRY5BAJAJNmzaVIUOGSJMmTbLGb9iwoRxwwAFZ4/AiCZBAdAJUZNFZMSYJ5CQwfPhwWbJkScZ4UGJ9+vSRtm3bZozDCyRAAvkRoCLLjxdjk0BWAjvvvHNWJQVL/siRI7PmwYskQAL5EaAiy48XY5NAVgJYcUFRZTIvIny//fbLmgcvkgAJ5EeAiiw/XoxNAjkJDBs2LK15sXHjxrL33nvLyiuvnDMPRiABEohOgIosOivGJIFIBHr06CHrrLNOStylS5fSrJhChQEkUDwBKrLiGTIHEkghMHr06BTz4korrZTyPllKQgaQAAnkTYCKLG9kTEACuQkMHTo0wbyIvTG45sNFn0ICJBAvASqyeHkyNxIwAhtuuKFssskmAQ245MM1n0ICJBA/ASqy+JkyRxIwAqNGjRI4eEDwix+9evWyY/4hARKIlwAVWbw8mRsJBAQOPPBAgYMHBC75cM2nkAAJxE+APxocP9OMOd577732e3wZI/BCvSPQtWtXefvtt6Vdu3Yybdq0etc+NigzAXivdurUKXMEXomNAH80ODaUuTNq3bq1fPfdd7kjMgYJkEDVE5gyZYocdthhVd+OamgAV2Rl7qXJkyfLH//4xzKXyuIqReCbb76RiRMnytlnn12pKrDcChBo2bJlBUqt3SJptK/dvmfLy0AATh6nnnpqGUpiESRQuwSoyGq379nyMhFo3rx5mUpiMSRQmwSoyGqz39lqEiABEqg3BKjI6k1XsiEkQAIkUJsEqMhqs9/ZahIgARKoNwSoyOpNV7IhJEACJFCbBKjIarPf2WoSIAESqDcEqMjqTVeyISRAAiRQmwSoyGqz39lqEiABEqg3BKjI6k1XsiEkQAIkUJsEqMhqs9/ZahIgARKoNwSoyOpNV7IhJEACJFCbBKjIarPf2WoSIAESqDcEqMjqTVeyISRAAiRQmwSoyGqz39lqEiABEqg3BPj/yOpNV0ZvyH333SfHH3+84H+j7b777ikJnXPy6KOPysMPPyz4r9bvvPOONGjQICVeIQGvvPKK3H333XL//ffLgAED5JxzzomUzSeffGJ1eeCBB2SvvfaSo48+Om26QvNPm1ko8PPPP5f//Oc/gvI7d+4sf/vb30JX8z9Eu7///vuEhGDctm1b2XLLLWWnnXaSlVdeOeF6sSd1rd8vvfRS+eijjxKaBQZo93bbbSc777yzrLLKKsH1n376Sf7973/bvfPII4/IwoULg2vFHsTdv8XWh+nzI8AVWX686kXsDz74wAYQfKeT5cuXy8cffyw33HCDfPjhh7EpMZSFweiNN96QOXPmCBRmVFmwYIEpESiTxYsXZ0xWaP4ZM/z9AnjMmjXLlHAcAyj+uSradPnll8v1118vXbt2NSX2/PPPm6Lu1q2blZerXvlcr2v9Pnr0aFlnnXWMATi0aNHCzsH30EMPlTZt2sgpp5wSNPGHH36QX3/9VR588MHY/9N63P0bVJoH5SGggwmlTARatWrldBVUptKyF6Mz4ewR9Or222/vmjZtmjNevhF0VQMN5saOHZtX0jvvvNPSjR8/Pmu6QvPPmqleVAVs5eu/r88VNdL1qVOnWn6qtBLin3vuuRbeqVOnhPA4Tupav6tysrbifgjXDceqyOzaQw89lND0rbfe2sITAmM4ibN/VSm7KVOmxFArZhGFAFdk5Zkv1LlSMBPOJQ0bNhR84pbGjQuzaDdq1ChSVQrNP1fmcecbNpuFyx4xYoSdYgUFs26cUtf6HQzSma1Rzx133NGaPnv27AQEcfeDz7xU+fr8+V06AoWNKKWrD3P+ncDSpUtFZ6Jy3XXXyYQJE+SKK66QV199Va699lpZa6215KuvvpLLLrvMTHQYDEaNGiV9+/YN+GEfatq0aWaCWW+99WSfffaRPfbYw66/+eabcuutt5oZByYuL08++aTljwF0iy22kK+//joYZGbOnClXXXWVLFu2TAYNGiQDBw6Uiy66yMpHeuy56QrOsoJpCGU/9dRT8vbbb8s222wjF198cWx7PqgD9nv+9a9/yaJFi2T48OFy4IEH+mZk/IZp8JZbbhG0f+211zZeQ4YMSYj/22+/Ge///ve/gj4A06FDh0q7du0S4uFkxowZctdddwlMsRDEw94WWOmqSs4++2w7t4t5/MF+IAQD6worrJCQsi73O9qNPSwoHuxzHXnkkbL33nsn1D+fE+xbQdKxT5dPlP5F3fAM4R7YdNNNZf/995c+ffqkyy5j/6aNzMDKEoiybGOceAjkY1ocNmxYYHLRzX/XsWNHO1cF5d5//32nDgfu6quvds8++6zr1auXXVOlZxXVAcXMMqqInO4nuV133dXpxrpdUwXmNttsM4t/5plnBg276aabnCpEp04Y7ueff3Z/+ctfLM6KK64YxEEeercGJkEdwN3hhx+eUDYiq8J0Xbp0caoU3GuvveZgZhk5cmSQjzqRJOQTXMhxoIOkpQNHmN122WUXM32iTqrsg9Tp8p84caLF1f0op/t+7rTTTrO8VCkH6dT5wvXo0cMdccQRDiYvn48OdBZHV0eWxpsWP/30U6crB/fnP//Z6R5LkM/pp59u8U444YQgLN0BWKPuYdMiTGrob4SDbVjqcr8/88wzTlfvTvdVne5juWOOOcbpCtq99dZbQRM8z2STsq7IrL3g++OPP7oXX3zRHXXUURamEyq3ZMmSIA8c9OzZ066FA6P0L+qmk0CnkxR7Lvxzg7pDovZvuNxMxzQtZiJTmnBsuFPKRCAfRYYqqdeWPbC68nK6CnEvvPCCfau3n9PN8KDWzz33nMXr0KGDhelM2Kn3m9OVkZ3jwdXVUxBfHSYsvldkUHgtW7Z0uqII4kCZ4WEMKzLsVYQVGSJjAEGYV6JI16xZM1OePjMoh/XXX9+fBgoieUALImQ48IoMitmLelVa+ag/lA8kecB89913XfPmzd0hhxzik9m3rp4s7T//+U87P/HEEy2ervKCeLqadOAK/uGBDgp6ww03dJhYJMs333xj+yNffvll8qWEc6/IMIHQlYHbaqutHAZ1DLYXXHCBU8eVhPh1ud919WksX3rpJauzb5uugIM2JPeLv+AVma7iLA/cT/hgMjR//nwfLfhOVmRR+lcdaxzyV2/RIB/UEcpXLQ0WFrV/gwyyHFCRZYFTgks0LeoTU1dljTXWsKrtt99+tlelCkF0xmrmG1WKgVkPpja4hGM/65dffjHXZV2tmXkQ5keYd7p37x40UxVNcIwDdTowV/DevXsH4TBp6cotKCO4kOMA6XSQl5VWWkngZXbzzTfbPg/qFZfAHOQFJlOYWuEBiHLhtp0s99xzT8AlfA1mw6effto8EWGa1c150VWeqPIOoumK10yM4b1CmKd0MDXzabrXF+Btp6u2II9cB6uuuqqZuOCpp8+4mSWT09f1fj/rrLPMfI1XB+B5ifsPooooV/OD6+g/VQDy8ssvW7+oMpcNNthAJk2aJAcddFAQL/kgSv/CJAuP1v79+wfJ8RoHXoGAGTQsufo3HJfHdYNA/Dv5daNd9aIWfvAMOzlgzwmC/Rc1wdgH707prNT2o3TlIdj3gWszXOf33Xdf2+fJ5rL++uuvW57YSwsLNuHxyVewp3HJJZcE70LpyiXfLPKKv8MOO1h8DFbpBGwgnqeP84c//MEOwVRNerbfhglCWLBPBaZhmTdvnilpuM3HIRi8sc+HfVCImuUECjQsdb3f1bvV9mPVo9D2oPr16xeufuRj8MdkQlfrouZt0RW+7bWpeTFjHlH6F0oS0rp164R8kpUYLsbdvwkF8qQkBKjISoK1dJn61YKaGVMKwUP/xRdf2ApCzWVy2223yZprril4eRQOGpkEDg6Q5MEzU/xs4VgdDh482BxV4AyBlQ4GuVIKnF0gaopKW8xqq61m4boXknAdbCDt27cP6oh3lJIHTUwCPCPEP/jggwWr19tvv93egUJYHALHG0xAUBacabDK9FLX+11fjbAJE1aSWNnGMXmBkxAE/D/77DOPIuU7n/7F6i1Zkl9ML1X/JpfL8/gIUJHFx7IsOcGEiFkkvAKxEvMCzzmYX/BiJ2b08PjCygyzS5gV4UH47bff+ugJ33j5FoJf8wgLvPa8Rx7CvXty+MFHHIiPB29JeFvutttu9kIrrsGzECazUskTTzwhugeXUZFtu+22VjTMiGHBihYCb0uYcWHig8clvCG9QDFjteQ9CRGOFTLirL766vbCLrw9kwVm1VzimflvxNc9R+svTEhgUvYr6bre7/BKBSvvBYo+h+Tq92zX/SoUL4tne20gSv/CTA5RpyYzMdqJ/sFzAbNoWKL0bzg+j+sAAb2RKGUikK+zh+6/2Ka3DsAJNTzjjDMsHE4CeHn273//u728rL+CYPF04HXekQMB8MLbZJNNzGEB595pwnsSwklCzYGW56mnnmpODTfeeKOd6y3q8AKyKkYHJwiUibhw7oCjh86GLZ6aMM0b0DuE6CrHwREDHn3IAx84RqhidXCuwLn+zBSqE1l8vY877rggDRxX4B0HRwIv6fKH5yHKVHd5H83pzNucYlTBW5j+uoTFQX64BhbwFj3//PPtuneq8Z6OqkCtbLy4q79UEuQLb1I4MMBhI5tcc801Vh4cUeDp5wXOC7hXUF9d3QZee3W533Vv0uoLb0WdZLmNN97YzlUZO10FWdPS9QvuB7QTH3Wft3hoP7xL4cCDcDVTezT27T14w840ufoXjjP6yoXlh7qp8nK6X+Z0Ve7gnAOJ2r8WOccfOnvkABTzZXotxgw0W3ZRFZnObJ2+F+WaNGliDx68t/TdlyBruLXDa1H3fOw6Bk24asNjEALXfTxI8HKDp57uV5ibPq5deeWVTvfCLB3iwA0dMnfuXPPCw8CBgRwu9PDKgys43O6/++47i3fhhReaJ6Ouzpxullu9oMzgKQm3adQd4agbBgnEh9clzuFmft5555lXHsoBDwzOUQUDjs74LR3csnVvzG2++eZOZ9VBFvBAg9dfcv7w4ARTdUZxau40D00od90fDNKi7uPGjbP2IT3ior66YjKlrCtbyxdth4ej7ruYokNc9JWaBi0vrxCzeWXCNV/3ayw/pEdd9N24oC6YBKBfcQ1thKKsy/0+ffp0h8kLOOhq3MF7cd111zWGUOjp+gUehHh9AW3EB+0Fc/DdaKONzJMzPPGA56E6LgXx4XWKew4SpX/13TEHL1RfHu5thEHAO2r/WoIcf6jIcgCK+XID5KcdSykDAWw048dmwy8hF1MsvLCw0Q2zk98nQn7wEISDgr7nZHs/+CHaqII08DjU2bDojDfty6jwoINJEe3BN24hHcASioBpTR/mICz5PLhQwAHKg3MGvAPDZUTJSpWhvVgOU5W+i5Y2CdqE/BEnuV1pE6QJxMvk+XBPk0XGoLra79hbxMfv54EjzuHJWi6J0r9wCoI5F3ujpRI8P2opyct7tVR1qYV8qcjK2MtxK7IyVr1kRUFZRvFww4/H4pczKCRQDQSoyMrbS43LWxxLI4FEAnjgx4wZkxiY5gzv0FFIgARIIB0BKrJ0VBhWNgJ4OTvbqwFlqwgLIgESqFoCdL+v2q5jxUmABEiABECAioz3AQmQAAmQQFUToCKr6u5j5UmABEiABKjIeA+QAAmQAAlUNQEqsqruPlaeBEiABEiAioz3AAmQAAmQQFUToCKr6u5j5UmABEiABKjIeA+QAAmQAAlUNQEqsqruPlaeBEiABEiAioz3AAmQAAmQQFUToCKr6u5j5UmABEiABKjIeA+QAAmQAAlUNQEqsqruPlaeBEiABEiAv35f5ntA/6Ot6H9GLnOpLI4ESKCcBPAPRSnlI0BFVj7WVtLkyZMFHwoJkAAJkEA8BPgfouPhyFxIIC2BCRMmyPjx42XBggVprzOQBEigeALcIyueIXMgARIgARKoIAEqsgrCZ9EkQAIkQALFE6AiK54hcyABEiABEqggASqyCsJn0SRAAiRAAsUToCIrniFzIAESIAESqCABKrIKwmfRJEACJEACxROgIiueIXMgARIgARKoIAEqsgrCZ9EkQAIkQALFE6AiK54hcyABEiABEqggASqyCsJn0SRAAiRAAsUToCIrniFzIAESIAESqCABKrIKwmfRJEACJEACxROgIiueIXMgARIgARKoIAEqsgrCZ9EkQAIkQALFE6AiK54hcyABEiABEqggASqyCsJn0SRAAiRAAsUToCIrniFzIAESIAESqCABKrIKwmfRJEACJEACxROgIiueIXMgARIgARKoIAEqsgrCZ9EkQAIkQALFE6AiK54hcyABEiABEqggASqyCsJn0SRAAiRAAsUToCIrniFzIAESIAESqCABKrIKwmfRJEACJEACxROgIiueIXMgARIgARKoIAEqsgrCZ9EkQAIkQALFE6AiK54hcyABEiABEqggASqyCsJn0SRAAiRAAsUToCIrniFzIAESIAESqCABKrIKwmfRJEACJEACxROgIiueIXMgARIgARKoIAEqsgrCZ9EkQAIkQALFE6AiK54hcyABEiABEqgggcYVLJtFk0C9IjB//nyZMWNGQptmz54tixYtkhtvvDEhvF27dtKvX7+EMJ6QAAkURqCBUyksKVORAAmECXz55ZfSoUMHwSPVoEGD8KWE4+XLl8uYMWNk3LhxCeE8IQESKIwATYuFcWMqEkghgFVW7969TYlBWWX6IOGwYcNS0jOABEigMAJUZIVxYyoSSEtg5MiRacPDgV27dpXNNtssHMRjEiCBIghQkRUBj0lJIJnAgAEDpFGjRsnBwXnjxo1l1KhRwTkPSIAEiidARVY8Q+ZAAgGBFi1ayF577ZVRmS1dulSGDh0axOcBCZBA8QSoyIpnyBxIIIEAzIvLli1LCMMJHEB69OghnTp1SrnGABIggcIJUJEVzo4pSSAtgT333FNWXHHFlGsNGzaUgw46KCWcASRAAsURoCIrjh9Tk0AKgebNm8sBBxwg2A8LC7wYBw8eHA7iMQmQQAwEqMhigMgsSCCZwIgRIwT7YV6wGuvVq5e0b9/eB/GbBEggJgJUZDGBZDYkECawyy67SJs2bcJBNCsm0OAJCcRHgIosPpbMiQQCAnDBHz58uDRp0sTCsCKDaz6FBEggfgJUZPEzZY4kYATgZr9kyRLzVoRLfsuWLUmGBEigBASoyEoAlVmSAAj07NlT1lxzTfvtxSi/+EFqJEAChRFI+dHgadOm0bOqMJZMRQIkQAIkUGIC22yzjTz//PMJpST6B4cu3XHHHaEzHpIACRRC4OOPP5bp06fLMcccU0hypiEBEggRuPnmm+WLL74IhfzfYUZFNmjQoJTIDCABEsifwD777CNdunTJPyFTkAAJJBDA//dLp8i4R5aAiSckED8BKrH4mTJHEggToCIL0+AxCZAACZBA1RGgIqu6LmOFSYAESIAEwgSoyMI0eEwCJEACJFB1BKjIqq7LWGESIAESIIEwASqyMA0ekwAJkAAJVB0BKrKq6zJWmARIgARIIEyAiixMg8ckQAIkQAJVR4CKrOq6jBUmARIgARIIE6AiC9PgMQmQAAmQQNURoCKrui5jhUmABEiABMIEqMjCNHhMAiRAAiRQdQSoyKquy1hhEiABEiCBMAEqsjANHpMACZAACVQdASqyqusyVpgESIAESCBMIOP/IwtHKvb4lVdekbvvvlvuv/9+GTBggJxzzjmRsvzkk0/k3nvvlQceeED22msvOfrooyOlS45UaPnJ+fC8vAQy9ZtzTnbddVdZYYUV7N4oRa2efvppueaaa+Sjjz6Szp07y7HHHitbb711xqIWLFhg9zfu8R122EH+/Oc/Z4yb7cL//vc/eeyxxwRtnz9/vqyxxhrStWtX2XbbbeX222+X888/X9Zcc027Xsln6qeffpJ///vf1uZHHnlEFi5cmLFZzz77rDz++OORn/uMGdXRC6+++qpMmTIloXYNGjSQNm3ayNprry19+/aVDh06JFwv9iQT/3I8Gz/88INcdtllgmekUaNGsvPOO8vJJ58szZo1k3Qs0NZVVllF2rdvb/dy7969pWnTpsUiSEhflhUZoL/xxhsyZ84cAeiogsEBSuw///mPLF68OGqylHiFlp+SEQPKSiBTvy1fvlww4ON+wnHc8s9//tMezv/+978ya9Ysuemmm6Rnz56CATuTfPnll4IBG/frsmXLMkXLGI52jBs3Trbccku54oorpEePHjJ27FjZd9995aWXXpJ+/frJDTfcIN9//73lkYlNxgJ+vxDXM4XB7Ndff5UHH3xQvvvuu6zF/uMf/5C//e1vOeNlzaQOX9xoo43kgAMOMGV2+eWXy2effSadOnUSsD7xxBNl3XXXLXhik6nZmfiX+tn48ccfZfvtt5eLL75Y5s2bJw8//LCcccYZsscee9izCBbDhg0T/CdnsHj55ZelW7du0qRJE8Hz1L9/f1lttdVsQpapbQWFq2JJkDvuuAOaJiEsjhN9wC1ffTjzyu7OO++0dOPHj88rXXLkQstPzofn5SWQqd90BeB0UI+9MshXZ47uqaeesrw//vhjt99++9k9qEoma3mq6CzehRdemDVeuoujRo2ytKqwnA5SKVHOPPNMu/7CCy8E1zKxCSJkOIjrmUL2ukq1emUoyoGfztotjiqzTNHqRfgf/vAHa6dOfIL2vP76665Vq1YWroN7EB7XQTr+pXo2UOfTTz/dqaJyurBwS5cudffcc49TJWXtu++++4JmqWKzsL///e9BGA7eeecdpysyu3bwwQe7JUuWJFzPdXLKKae4bbbZJiVaWVZk0LCNGxdmxcTSNQ4ptPw4ymYehRPI1G86OEiLFi0KzzhDSpjrYCbZaaedLAZMQ2effbYdw2ySTRo2/L/HyX9nixu+NmPGDLnxxhvNVDp58mQzw4Sv4xjm+PXXXz/BMpGJTXLa5PO4ninkm6sOkyZNMnMS4l555ZUFrVaRthoE5rNkwQqlV69eFozVa9ySjn+png3VHmYihsm9efPmZlaExQCmUwisJF4yPZu4h3UiJeuss47A8nHcccf5JEV9F6Zd0hT5/PPPy4QJE+TDDz+UDTfcUFRryuabby4rr7yyLS3TJLGgX375xW5wmHBgPsQyFI3D3kBYYK5RjS//+te/ZNGiRTJ8+HA58MADgyiw0U+bNk10Ji1vv/22lY/lL8ovVmbOnGn7AbNnz7b8jjzySNl7770tW5iDEA5B51111VUWx4e3bNnSTEK4/tVXX5ltGSYx3PQ6Cw9uAuzFwISFGwQMYI6BOemEE06w/YdcbYvCP1v5qF8ugTkDfYC6XHrppWY+ePTRR62vMNij3l6i9iv6/ZZbbpE333wz2E8YMmSIzybtN+4TXY3Irbfeag8FBmaY3+666y5jv+eee9r+1ltvvSU665ORI0cm5JONFUwkq666akJ8mPsQttJKKyWEox4XXXSRmRRhOunYsaNdx/6IF9w75557rilDrxz9Nf8NEyJkxIgRstZaa9lx8h/sKWBPKvm5SI6H86jsS/1MwfR47bXXCu4RmJt0dWJ9NHjwYKv2+++/LzrDF53ZC5jhecY13AtggvRHHHFE8Izo7F/w+eKLL8wEe9pppwmeL6R/6KGH5LrrrrMxCKZZTDpQNnhme35REZSDsQJ7PpiEYOzCfigmMRhw27Zta/XNVL5dzPLH3w9+AhG1f+ras7HZZpvZPm3ymLr77rvL9OnTI+8DYu8QumL//fe3dJjsFC3Ja7RCTIvPPPOM05mBu+222xyWtWpDtaWj3kTuoIMOsiLUlmpheoMGRX7zzTdO4bhddtnFqb3VIR+9cWwpjmOIPryWDstztTtbXH2oLUxhBHlhKdulSxf322+/uddee82pUnE6gAXX05UfXMxygHroze10f8LpDe+OOeYYM5XoIGmpsLzGUlc7wukMI8gJ5iG9gZ1u2luYPrROnQbc1Vdf7XQvxekszdLow+d0I9zpQ2PnOglw6623ni3XdSJgaXO1LQr/bOUHlc5xcPzxxztVtFZP9MXQoUOdDs52roO8QxmQKP2KeBMnTnToy+uvv97pBMjpwGR5DRo0CJdNkvtN96LsnsL9BuYwTaC/dQ/LznWgd5tuuqn1Pe4Z9J1ONHx2do/luleDyL8f6B6Q9eXhhx8eXEL/brXVVk5t/nbP6x6w9RvqFDahwRSDMJ2QBGnDB7qn4XRSY3EuueSS8KWcx8lskCAK+7ieKZTnueM4WfDMqOOLBesEz9qI+GGBOQp8dBIQDnZ/+tOfzKTrA8866yynTgXWf+pYYc/HBhts4H7++WczdSEPfGD+RV441tW1xc/2/CJ/mHN1T9Lp/o/D+IfnFulhAtPVslUhW/m+jsgH6cKmRZjSWrdubeE60YrUP8gvyrOBeGH+lXg2UIeTTjrJnmM8w17wDINFsmnRX//000/tOuK89957PjjndybTYspmWCGKDA+zzjbMZoqaqKehVTL84Kd76A477DC7aXQ1EjQANw4aB6UExeEfOvVSC+L4/HU2ZvsJuJnVY8aF4+DG1GVskCZd+cHFLAe60rD66IzfYqlXmp3rKiJIpZuYFoYb2QvqCAXkRb013aGHHupP3XPPPWdp1JvJwp544gk7x0AM+7N6rNknStui8M9VflCxHAdeAYOnl0MOOcTqrrNnC4rSr++++64pRaQNi1eMflKQqd/85MHb2JEf7ptNNtnEqSOEZYnBAGG6egyKiMIqiPz7ga6uHe419aINLmFgQ95+QoMLF1xwgYWFFRkUCwZeDDLpBHtIyAcfXemmRMF1TPSgnPHB5Oavf/2rxUvHJgr7uJ4pVCI8kCZXHopeV80WDCWBySXaqSvihKh4bpPDt9hiC3tGEBGTQYwvYOEFzxbSqJnLgqDkcK7edE5Xmg57ifjO9fy++OKLlk5XzT5rh7KRFwZbSJTyEc8rMrXYODURO/V0tf1W1N1P4KP0T9RnA2Wm41/OZwP71Oq84U499VRUJ5BcigwRMdEE53z2DjMpslj2yGCygplCNavWS2S77baz72+//da+0/3RdtgyFW6pWL572XHHHc2EozMZMw/4cCxDveyzzz5mMoAHl87GbW8B3zBRwfwF8x7Sw325WNEBS/ShMFMGTFK6orIsw3nrJq+ZUXVgMXdtRIBZAyZICDx9dPAwswq80fA56qijzK0by3SYGrzJSB9QMy/CJIIPXMxztS0X/yjlW0Uj/PHmte7duwexwQjivVLhJp6rX2GmQbv9veIz8/Z27FVlE7j6hgWcIDAH+TpuvPHGFgaPQi+5WPl4/lsHT9GVkugEL+gjXIM5BG7wcI33ApMUxJuScAwzig5e5qmF82SBOdrHh6kyWdAeuK6vvvrq9jygTZ53cty69EzpRM2eBbxuA0+6FVdc0UynqDPM5mHBqw0Q7L1A4OmGNP7ewHON8QV5+efHvxbhvTj986OOOWYeRDyYCXM9v7gfINiO8IJXHSB+/IpSvk+Lb+wVYbsBbYbJHXWFeTlq/1TLs4G2Yu8WWwrq4ITTyIJnH563EHgxFiuxKLI+ffpYPfDOFwSu9hA/KNlJ0h8MLhhgcbOFBZuX/kYK31zhODjGuzoQfyO2a9fOBhzsQ0A5YJ8uDsHeBNyLYTOHctJZV9ps1eRoDx/eJ9GZnMydO9dcTRHZtwM3tc4A7YP3hHTmZdewL+Y5eDt6uJBcbcvFP0r54fLyPVZTjtUfnKL2K9oO8e32ZWJSAPF19uGFfKdjmYtVuBzsxWLShP1O7AN4QRt1pWUu1j4M314h+e/wtUzH2ONRU7JdxuQrk/g4uA8zSVT2mdLH+UzBsQOMsLeI5xEfOLJAsNkP13Qv2G+GwtatCXu9AM8Q9sa8YK8TCt8/O/jGGIN7SFcCFs3fR8l9nuv5xcQZkyK8u4f+hmCPDi7zarq08yjlW8Tf/6DuaAP23TAuYMIDido/1fBsoD1wscf+J/oT43Y+Atd9vzfqJ4D5pE+Om6hFkq9GPMd7BJgt4RsrDbw7gY1YNRtlzEHtxtZ43NCYsYTFdzxeoMsk3kNITZA2W8MmMTZ84QEGJwrcwHEIOgkKGbNq3JyZFCScT+AtpPs99sCiDr5zMTODYGWXLGo6tM3r5HB/jplorrbl4l9M+b4e2b6hdDCDRl9E7Vc/C9P9vYSso/R9QoI8T3Kx8tmBu3coUhO5D7Zv3Ye1bziYwFGgWMFgCsFMHOWmEz9QZ1OSUdmnyx9hcT1TeI8KK2o817i//UfNwDZJxQAGRecFygfWC8SDsoNDEdh7wf0LSwsUSrJ88MEHyUEJ57meX6ze8Z4qVgdqNjcFCoUDC0r4+S20/HBlovZPXX820Ca8M4kJHhQZxr18BXwhWLSAS7ESiyKDSQSzL9y8MBOgkZiNZHvooGi8eQreQmHBjAumIn89fM0f656SuSNj8ES5UGK77babmXIQB7MrLOWLFbQDg4v3pPOztuS88bCNHj3aXoY877zzTPH5svHLEJiRwtsPKzEvGPzVGUZgvsokUdqWi38x5WeqVzgcfQHBr69E7Ve/6k7X98gLL12WQnKxQpnoWygvmPHGjBkTVAMDMWbbMPnCZIi8wooYAzQE/RoWDILZBKZLKHCYpMIDfLY06a5FZZ8uLcLieqbgNYhfb8AqK1nUYciCoLCguLxgooj6YwIMqwdWYF78OKDv0iU80/BGhNdjNony/MJ7ElsXui9rpkiY8n2ZyNsf5yrf93vy2ODrF7V/6vKzgbbA2oTnAJ7D3qSLcEwI4DkM8SzsJOkPXjWBty9W61OnTk26WuCpQk+QQpw9dAC3jTtsQmPzFd5K2ij39ddfB3lj816r6PRnpoIwHcTM2QMv9emgYOHwfFEF6FQZ2LnfmFaX/CAd8tZZnPMOB6rELG+8yAonC/15IDtHeaoIzCMyXflBhlkO1E5vecFbEZvxOrjZOV6S1Rl0Qkps/KPu6v6dEI4TXQlYOnioYWMZ3jzw7sTmJUQfSruOjf2wRGlbFP65yg+Xme1YlZXVU1enFg2OFdhchrclPEYhUfoV8dTMZ3nBm8sLXpJUd2en+xMWlKnf4PSA/vUeT3DGwXnYKw4OOQgLOx1FYaXvkVk6dYd3/qOrYmuj7y99EC0OPORUAdg95l+IRb/qTNXqDy9V3BNwBMkm8DzVmanFhfemfx6QBix83qokgmzSsYnCPq5nChXxHoK6irF6ff755+bUob/qENQzfIB2+Rdow04xiKOrMGMa9jJFOMYR79mJe0b3J51afqxsteggilPTr6VF+8OS6/mFp62udp2aNx3qrNsH5n0dfvE8SvkoU/eKrA7+HgnXwx9H6R/EjfJsIF4yf4SV8tnwXphw5PHPBr51EeF0cmdemagDxgM8e7iXIeh3PKMY/3Wl61SJ2XNjF/P4k8nZAzOcBClEkeFhRaWTP/BKwS8kwPUWrvi4jjAMql7gfguvF531mBsnPA3h4aOrIIsCry9dDVk6eBPBnRcd5X95AZEQFwMsbkid2Tr8sgK8l3COmwtKMVP5vh6ZvvX9CPM8wsOHzkJnqP3c6Yox7eCEBwrKNFkwyMNrEXUCBwxuGGB1VurAwHc8FLT+3E3g5ZarbVD8ufijLtnKT65rtnOvyMAVCgxc1TTmMICFJVe/Ii5e1dB3h4ylmmLNnR9eh/g1BEi6+0bNVW7gwIHGDxwxUGFCgckQzsEXHlR4xQGvCCAMHod4zQGSixUUNNJk+mCyAsFrFyhHZ9kWV/cxbSDGgAtl7AdUDI7Iy3utWeIMfzBgYsIE7z7cb3gm0C4odihH/LqNnyykY+OzzcU+jmdK33Gywd9zgrepzrRtgEIYXqPB6zhhUZNj8CspiAN2uuINomAyh2c8neAaPHp9eRjA4eGM5wP3kFeO8HaGMvKS6/mF1x1ed/H5hr91leazsYlmuvIRQVfS5jHt06p1xiazuL/TSa7+QZpczwYUOJSvLxP84VFdymcD9x7GPl9m8jd+8QOvUfnJg78OHhj3cS9D6WECg1daCpFMiqwBMtMCA4H5C3syScHB9XQH+h6BbZjCtAbnC5gMYHPGC4qw92IpmU30ZrTNWzh/wAPGe52F06A+sLnDpBM2O4TjwIQTvpZ8Ho6bzzFMSvjAfAiBCQnn3lMunBc8nWDzVUUVDg6OwQWbuTD3+T2J4GKWg+S2hM/z4V9o+b5q6r5uJgXsg6Cf4awAE0E6idKvSAezNF5ghfeqKp90WcUWlg+rKIXqw22OC6g3eKDf/X3i06uCCl6q9WG5vuEwBJMXTI46eGS8nzLlE4V9JZ+pTPXOxgr1hWc0GMP5JdMzlpx3tucXTiP6PqT9GAH2OzEG6epBsPcGMyfMjP6eLLT85PrgPEr/IF41Pxuof9wC5x6dJAo8yMOSn6tJOOXvx3BDxlvaUGB4Az7sDIEBPdsPrfrssNmr78j407TfuGnX1Qc6m4SVGOIln4fTqhnUNtfDYcnHSP+E7v/obM8+/jo2gf1GsA/z31C02QR7Zd7mni1e8rXktvjzfPmnKx+b25m8McP10NlQcKorn8DbLghMOojSr0gCRajvASWljv80X1ZRaoB9D+9RmG4Chjz8L0NEyc/Hwd5DeP/Bh0f9jsI+7mcqat2yxcvGCvXFTxzlK5meXyg4eKNibxcT6LBAacELOzxJK7T8cL7+OEr/IG41Pxu+reX4LlqR4X0ACDbH8Q6HLvltJgmNCTfW2DbzYqaBmzesdNNln27FlS5eJcPi4I9VVdipIVN78G4OftEagn+xg9cCqkniYFVN7WVdsxPAqgjKDA4KWHVhMg0FA+9iuOPrS71ZJ8PZc6+uq1X/bOjMI0Hy3SNTAE5finPqaWMOGPiFDdj28WsKcASglJZAufhjTwj7WNio1UfUfgoITj3VJOViVU1Mar2u2MvEHhv2OHFf+71O/PJOLUm1PBsl3SPzcw+FYXtlWIJTyk+g1PzxwnNY8CI3PtUopWZVjUxquc6qtOyXZqrBClPqfqrLz0bJ9sjCUKt1UAu3oZqPS82/kBcf6yrPUrOqq+1mvdITwOSbSuz/2FTjsxHLC9Hpbw2GkgAJkAAJkEDpCVCRlZ4xSyABEiABEighASqyEsJl1iRAAiRAAqUnQEVWesYsgQRIgARIoIQEqMhKCJdZkwAJkAAJlJ4AFVnpGbMEEiABEiCBEhKgIishXGZNAiRAAiRQegJUZKVnzBJIgARIgARKSICKrIRwmTUJkAAJkEDpCVCRlZ4xSyABEiABEighASqyEsJl1iRAAiRAAqUnkPHfuPCHf0sPnyWQAAmQAAnkR0D/M31KghRF1rNnT9F/5ZISkQEkQAL5E3jggQdk+vTpcvXVV+efmClIgARSCKT758UN8D93UmIygARIIBYC+O/p48ePlwULFsSSHzMhARJIJcA9slQmDCEBEiABEqgiAlRkVdRZrCoJkAAJkEAqASqyVCYMIQESIAESqCICVGRV1FmsKgmQAAmQQCoBKrJUJgwhARIgARKoIgJUZFXUWawqCZAACZBAKgEqslQmDCEBEiABEqgiAlRkVdRZrCoJkAAJkEAqASqyVCYMIQESIAESqCICVGRV1FmsKgmQAAmQQCoBKrJUJgwhARIgARKoIgJUZFXUWawqCZAACZBAKgEqslQmDCEBEiABEqgiAlRkVdRZrCoJkAAJkEAqASqyVCYMIQESIAESqCICVGRV1FmsKgmQAAmQQCoBKrJUJgwhARIgARKoIgJUZFXUWawqCZAACZBAKgEqslQmDCEBEiABEqgiAlRkVdRZrCoJkAAJkEAqASqyVCYMIQESIAESqCICVGRV1FmsKgmQAAmQQCoBKrJUJgwhARIgARKoIgJUZFXUWawqCZAACZBAKgEqslQmDCEBEiABEqgiAlRkVdRZrCoJkAAJkEAqASqyVCYMIQESIAESqCICVGRV1FmsKgmQAAmQQCoBKrJUJgwhARIgARKoIgJUZFXUWawqCZAACZBAKgEqslQmDCEBEiABEqgiAlRkVdRZrCoJkAAJkEAqgcapQQwhARIohMCyZcvkt99+S0iKc+ecLF68OCG8QYMG0rx584QwnpAACRRGoIE+ZK6wpExFAiQQJjBnzhzZYostwkEZj4cNGya33nprxuu8QAIkEJ0ATYvRWTEmCWQl0L17d+ncuXPWOP4iFBmFBEggHgJUZPFwZC4kYARGjRoljRtnt9i3aNFCdt99dxIjARKIiQAVWUwgmQ0JgMDQoUNl6dKlGWE0adLE4uCbQgIkEA8BKrJ4ODIXEjAC66+/vsDECGeOdLJkyRKhWTEdGYaRQOEEqMgKZ8eUJJCWAMyLDRumf7TatWsnO+64Y9p0DCQBEiiMQPqn6XolHgAADNRJREFUrbC8mIoESEAJDBkyRJYvX57CAubEgw46KONqLSUBA0iABCIRoCKLhImRSCA6gQ4dOtiqK3lVRrNidIaMSQL5EKAiy4cW45JARAJYeSVLp06dIr9nlpyW5yRAApkJUJFlZsMrJFAwgYEDBybsk8GsOHr06ILzY0ISIIHMBKjIMrPhFRIomECrVq2kb9++0qhRI8sDZkW45lNIgATiJ0BFFj9T5kgCRmDEiBGB00e3bt2kS5cuJEMCJFACAlRkJYDKLEkABPbee29p1qyZwaBZkfcECZSOAH80uHRsayLnW265Re67776aaGshjZw1a5bMnz9f+vfvLyussEIhWdREmjvuuKMm2slGloYAV2Sl4Vozuc6dO1cee+yxmmlvvg3t2LGjrLbaalRiGcBByU+bNi3DVQaTQDQC2X/dNFoejFXjBPCzTJxRp78J8LuL06dPlwEDBqSPUOOhuG/wAjmFBIohwBVZMfSYlgRyEMAv4VOJ5YDEyyRQJAEqsiIBMjkJkAAJkEBlCVCRVZY/SycBEiABEiiSABVZkQCZnARIgARIoLIEqMgqy5+lkwAJkAAJFEmAiqxIgExOAiRAAiRQWQJUZJXlz9JJgARIgASKJEBFViRAJicBEiABEqgsASqyyvJn6SRAAiRAAkUSoCIrEiCTkwAJkAAJVJYAFVll+bN0EiABEiCBIglQkRUJkMlJgARIgAQqS4CKrLL8WToJkAAJkECRBKjIigTI5CRAAiRAApUlQEVWWf4snQRIgARIoEgC/H9kRQJkchLIRuCTTz6Riy66SE4++WTp1KlTtqhpr11yySWyYMGChGv41zBt27aVDh06yM4771xQvgkZ8oQEqpwAV2RV3oG1Xn3nXEkRFJr/F198ISeeeKLgn45eeeWV8tNPPxVUz9GjR8vy5cvl8ssvt8/aa68t6667riD/cePGyXrrrSfbbrutvPvuuwXlz0QkUB8IUJHVh16s0TZggN91111l2bJlJSFQTP6ffvqpHHXUUbLddtsVVbfVVltNhg8fbnmsssoqcsopp8hxxx0nEyZMkNdff12mTJkir7zyivTs2VOef/75ospiYhKoVgI0LVZrz7HecsYZZ8gTTzwhha6aciEsJv8tttjCsscKqlhp0aJF2iwaNWokhx12mHz//fem4Hr37i2vvfYaTY1paTGwPhOgIqvPvVtH2/bLL7+YuW3WrFmyePFi6datm60y1lhjDavxn/70J8HeUoMGDWTq1Kny1ltvyXnnnWcrL+wNwVQHJXPxxRdb/EMPPVTWWmstueCCC2x1cvvttwvyggnutttukw8//FD69+8vp59+uq1arrrqKstr0KBBMnDgQNvDmjNnjuV1/PHHy/bbb58x/ziRzpw5U84991w5++yzZaeddio4a+y/3XzzzTJ37lx57LHH5I9//KPldc899wg+MENuueWWctppp0nLli3t2ksvvSR33XWXrLzyyrLnnnvKNddcY5wPPvhgGTlyZFCX+fPny7XXXiuzZ8+2uB07dpTx48cH17OVEUTiAQmUmoDOZikkUDABNXW5rbfeOnL6b775xm222WZul112cfPmzXPPPPOMW2eddVyrVq3sGBktWbLErbrqqtj8CvLVAdU1bNjQ6QrHwlQJug022MDi6KrM4fzJJ590OmBbWOvWrV337t3dIYcc4nCMvNTUZ2kvvfRSOx87dqydqwnRHX744RZ23XXXZczfLuT5R5WC5Yu2JosqVrt2wgknJF9KONdVlsVT02JCePjE1x/lQc466yynjiDGVM2PrkmTJsbr559/dshPTZGWpyp8t+mmmzqkQx+AsSqtIOsdd9zReU4PPfSQsfQXs5Xh4+T61kmH1SNXPF4ngWwE/v9IkS0Wr5FABgL5KjI1hTldabmPPvooyHHGjBk2mHXp0sX9+uuvFq57SykDXLt27QJFhkg9evSwvIKM9ADKDEprhx12cFBQEF3RuebNmzs1xTkoRAzIiOMHaMSZOHGihXlFhrB0+SM8H8mmyKDUoWS+/PLLrFlGUWS6Z2b179y5s9M9M2vrxx9/HOS7xx572HVdeVmYOofY+SabbOLUEcXCPAMoeoiuZC3O+eefb+f4s9dee9lxlDKCRFkOqMiywOGlyARoWtQRjVIeAnpXCsx+cBvXVVhQqM76ZaWVVpJ33nlHXn31VTODBRdzHMD8GBbkA4G50l/r2rWrDB48WG666SbL34eH02U6zidupjwyhbdp08b2uDJdzyf8q6++suhwDrnlllvMdDpgwIAgi0WLFokqOdtPQ+AKK6xg17CH55ltvPHGFqaK1b7RR3hlQFdeAhMjzLsw9UKilGER+YcEykCAiqwMkFnE/xHAAPnjjz8G+zSeC96Lggu5rszk7bffLkqR+TyTv+GmDvnuu+9ETY3JlzOel1KRZSy0gAsvv/yypQJH7CnCQeTFF1/MKyc4j4QFbb/++utl6NChtocGJYb9xREjRhRcRjh/HpNAXATofh8XSeaTkwAUCJQWXvBV02JC/DXXXNPO27dvnxCe6ySqonnjjTcsKzVf5soy4XrU/BMSlfnk888/FzjOQPr16ycrrrii/PDDD6ZskqvywQcfJAdlPMdrDXh9AE4kw4YNszxHjRplE464yshYOC+QQB4EqMjygMWoxRFo2rSpqAOGZfL0008nZIbVA8xd/joUHgQDMgRmSQyseLfLC5QMwpYuXeqDMn7r3pmZM9XRxJQpIsJt3YvPo9D8fT75fvv2ZUsXrlNyPKSH8lq4cKHA21P3wgKGZ555pnHzaeAlCc/NqAKlhzx1b1JuvfVW0f1D4w9PRd9PxZYRtS6MRwJZCUTeTWNEEkhDIF9nD1Vg5qABT0d1vbcc4VSgSsnpHkxQAo71xnXqIu/uv/9+p27y5lGHePfee69TBeb23Xdfi3P11Vc7OGnAKeKFF16wMHg0qhnT8rvjjjssTPfI7Fz3ixw8AOE8gnRwctC9JYuDPFEfSLr87UIef+A5iHbAszJZUG+0R18bSL6UcK6vEFge8DxU5WtOLOpS79TsZx6gyF/3AJ0qY0v39ddfW/sQ3qdPHzdp0iTz2FTXeaerYYuj7veWJ7wXvei+l4XBAxKie5bmPfrZZ5/Zua787DrqE6UMS5TjD509cgDi5UgE6LUYCRMjZSKQryJDPvfdd58pDrjHn3TSSU5/xsk8CKGcvMC7EG76GIzhcj958mTzItT3rRy86jBo6yrBFAGUgb5LZQO8V2RIo/ti5mYOV34M5mG58MILnZrHnK78zBNP35WyOh155JFOV4cWNV3+4TyyHT/33HNOnS3MexBtgHfgOeeck5BEf3bK2hf2nkyIoCdw0dd35ywe8kF9UW+0TVdiDq77jz/+eHIyp6svB9d6pMEHSgzeoZD33nvPXplAONztTz31VPfss886deywuPqumSl4KDK45CP82GOPdX379rX+8t6g2cpIqVCGACqyDGAYnBeBBoitNzSFBAoioIOgPPXUU/bCbD4ZwCSIfSs4f8DD0HvOJeehLuQCzzpVVqLvQNn+TziOrgxEB2OBByAEJkpd7dnPQ+HHerF/hN87RJxkQdkwKWLvDt94FHTVkxAtOf+EizGcIH+85F0KQXtUaRk7OLuAYT4Ckya4oK/wgjrySOZYbBm6WpYhQ4YkmEDzqSPjkgAI0GuR90FFCMBDTl/EzVl22E0fDgbJkk0JwHMv0887IR/8dqEXvyfnz/23zx8el9iLyiW6QjUvv1zx/HWfvz+P8xuKC0q8UIHSwr4mJFM+xZZRaN2YjgTCBKjIwjR4XPUE9CVjawNWEHEKftppzJgxObPUl6hzxmEEEiCBeAlQkcXLk7lVkID+YofonpvV4NFHHxX8biB+jxFed8VKs2bNBL/NSCEBEqh7BKjI6l6fsEYFEujVq5eok0VCanVWSDjnCQmQQP0jQEVW//q0Zlukv6co+FBIgARqi0CqK1dttZ+tJQESIAESqHICVGRV3oGsPgmQAAnUOgEqslq/A9h+EiABEqhyAlRkVd6BrD4JkAAJ1DoBKrJavwPYfhIgARKocgJUZFXegaw+CZAACdQ6ASqyWr8D2H4SIAESqHICVGRV3oGsPgmQAAnUOgEqslq/A9h+EiABEqhyAlRkVd6BrD4JkAAJ1DoBKrJavwPYfhIgARKocgL8rcUq78C6UP13331XBg8eXBeqwjpUGQH9T+BVVmNWty4SoCKri71SRXXafPPNpU+fPlVUY1a1LhHAf//Gh0ICxRBooP+q3BWTAdOSAAmQAAmQQCUJcI+skvRZNgmQAAmQQNEEqMiKRsgMSIAESIAEKkmAiqyS9Fk2CZAACZBA0QSoyIpGyAxIgARIgAQqSeD/AepmZBvZoBlVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.utils.plot_model(model, 'my_first_model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-21T00:51:30.297066Z",
     "start_time": "2019-10-21T00:51:30.291578Z"
    }
   },
   "outputs": [],
   "source": [
    "# PARAMS\n",
    "NUM_ITER = 30\n",
    "\n",
    "# Use tf.Variable contraint \n",
    "UPPER_LAMBDA = 1\n",
    "LOWER_LAMBDA = 0\n",
    "BETA = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-21T01:53:35.220111Z",
     "start_time": "2019-10-21T01:53:35.217693Z"
    }
   },
   "outputs": [],
   "source": [
    "# Surrogate loss로는 cross entropy를 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-21T01:53:35.988309Z",
     "start_time": "2019-10-21T01:53:35.426320Z"
    }
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=[32, 32, 3], name='img1')\n",
    "\n",
    "x = ResidualBlock(2)(inputs)\n",
    "temp_x2 = keras.layers.GlobalAveragePooling2D()(x)\n",
    "temp_output = keras.layers.Dense(100)(temp_x2)\n",
    "\n",
    "x = ResidualBlock(2)(x)\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "output = keras.layers.Dense(100)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-21T01:53:39.485200Z",
     "start_time": "2019-10-21T01:53:39.477723Z"
    }
   },
   "outputs": [],
   "source": [
    "model = keras.Model(inputs=inputs, outputs=[temp_output, output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-21T01:53:40.091669Z",
     "start_time": "2019-10-21T01:53:40.009233Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  loss='sparse_categorical_crossentropy',\n",
    "  optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-23T07:13:51.688076Z",
     "start_time": "2019-10-23T07:13:39.625781Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of epoch 0\n",
      "step 0: mean loss = tf.Tensor(0.3169254, shape=(), dtype=float32)\n",
      "vae losses[<tf.Tensor: id=527570, shape=(), dtype=float32, numpy=0.08047132>]\n",
      "step 100: mean loss = tf.Tensor(0.12541005, shape=(), dtype=float32)\n",
      "vae losses[<tf.Tensor: id=546488, shape=(), dtype=float32, numpy=0.00065419014>]\n",
      "step 200: mean loss = tf.Tensor(0.09926062, shape=(), dtype=float32)\n",
      "vae losses[<tf.Tensor: id=565191, shape=(), dtype=float32, numpy=5.6293735e-05>]\n",
      "step 300: mean loss = tf.Tensor(0.08921422, shape=(), dtype=float32)\n",
      "vae losses[<tf.Tensor: id=583894, shape=(), dtype=float32, numpy=5.96678e-06>]\n",
      "step 400: mean loss = tf.Tensor(0.08425562, shape=(), dtype=float32)\n",
      "vae losses[<tf.Tensor: id=602597, shape=(), dtype=float32, numpy=3.6250567e-06>]\n",
      "step 500: mean loss = tf.Tensor(0.080906875, shape=(), dtype=float32)\n",
      "vae losses[<tf.Tensor: id=621300, shape=(), dtype=float32, numpy=9.570795e-07>]\n",
      "step 600: mean loss = tf.Tensor(0.078771226, shape=(), dtype=float32)\n",
      "vae losses[<tf.Tensor: id=640003, shape=(), dtype=float32, numpy=8.317991e-06>]\n",
      "step 700: mean loss = tf.Tensor(0.07716627, shape=(), dtype=float32)\n",
      "vae losses[<tf.Tensor: id=658706, shape=(), dtype=float32, numpy=3.3769174e-07>]\n",
      "step 800: mean loss = tf.Tensor(0.07599041, shape=(), dtype=float32)\n",
      "vae losses[<tf.Tensor: id=677409, shape=(), dtype=float32, numpy=1.1053344e-06>]\n",
      "step 900: mean loss = tf.Tensor(0.07496884, shape=(), dtype=float32)\n",
      "vae losses[<tf.Tensor: id=696112, shape=(), dtype=float32, numpy=9.124051e-06>]\n",
      "Start of epoch 1\n",
      "step 0: mean loss = tf.Tensor(0.074689455, shape=(), dtype=float32)\n",
      "vae losses[<tf.Tensor: id=703226, shape=(), dtype=float32, numpy=4.861504e-07>]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-1a49b34acc21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_batch_train\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m       \u001b[0mreconstructed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m       \u001b[0;31m# Compute reconstruction loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmse_loss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreconstructed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    890\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-1a49b34acc21>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     67\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mz_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_log_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mreconstructed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0;31m# Add KL divergence regularization loss.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     kl_loss = - 0.5 * tf.reduce_mean(\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    890\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-1a49b34acc21>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    890\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1056\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1057\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1058\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1059\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mbias_add\u001b[0;34m(value, bias, data_format, name)\u001b[0m\n\u001b[1;32m   2716\u001b[0m       \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m       \u001b[0mbias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"bias\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2718\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_nn_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mbias_add\u001b[0;34m(value, bias, data_format, name)\u001b[0m\n\u001b[1;32m    740\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"BiasAdd\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_post_execution_callbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data_format\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 742\u001b[0;31m         data_format)\n\u001b[0m\u001b[1;32m    743\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "class Sampling(layers.Layer):\n",
    "  \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "  def call(self, inputs):\n",
    "    z_mean, z_log_var = inputs\n",
    "    batch = tf.shape(z_mean)[0]\n",
    "    dim = tf.shape(z_mean)[1]\n",
    "    epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "    return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "\n",
    "class Encoder(layers.Layer):\n",
    "  \"\"\"Maps MNIST digits to a triplet (z_mean, z_log_var, z).\"\"\"\n",
    "\n",
    "  def __init__(self,\n",
    "               latent_dim=32,\n",
    "               intermediate_dim=64,\n",
    "               name='encoder',\n",
    "               **kwargs):\n",
    "    super(Encoder, self).__init__(name=name, **kwargs)\n",
    "    self.dense_proj = layers.Dense(intermediate_dim, activation='relu')\n",
    "    self.dense_mean = layers.Dense(latent_dim)\n",
    "    self.dense_log_var = layers.Dense(latent_dim)\n",
    "    self.sampling = Sampling()\n",
    "\n",
    "  def call(self, inputs):\n",
    "    x = self.dense_proj(inputs)\n",
    "    z_mean = self.dense_mean(x)\n",
    "    z_log_var = self.dense_log_var(x)\n",
    "    z = self.sampling((z_mean, z_log_var))\n",
    "    return z_mean, z_log_var, z\n",
    "\n",
    "\n",
    "class Decoder(layers.Layer):\n",
    "  \"\"\"Converts z, the encoded digit vector, back into a readable digit.\"\"\"\n",
    "\n",
    "  def __init__(self,\n",
    "               original_dim,\n",
    "               intermediate_dim=64,\n",
    "               name='decoder',\n",
    "               **kwargs):\n",
    "    super(Decoder, self).__init__(name=name, **kwargs)\n",
    "    self.dense_proj = layers.Dense(intermediate_dim, activation='relu')\n",
    "    self.dense_output = layers.Dense(original_dim, activation='sigmoid')\n",
    "\n",
    "  def call(self, inputs):\n",
    "    x = self.dense_proj(inputs)\n",
    "    return self.dense_output(x)\n",
    "\n",
    "\n",
    "class VariationalAutoEncoder(tf.keras.Model):\n",
    "  \"\"\"Combines the encoder and decoder into an end-to-end model for training.\"\"\"\n",
    "\n",
    "  def __init__(self,\n",
    "               original_dim,\n",
    "               intermediate_dim=64,\n",
    "               latent_dim=32,\n",
    "               name='autoencoder',\n",
    "               **kwargs):\n",
    "    super(VariationalAutoEncoder, self).__init__(name=name, **kwargs)\n",
    "    self.original_dim = original_dim\n",
    "    self.encoder = Encoder(latent_dim=latent_dim,\n",
    "                           intermediate_dim=intermediate_dim)\n",
    "    self.decoder = Decoder(original_dim, intermediate_dim=intermediate_dim)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    z_mean, z_log_var, z = self.encoder(inputs)\n",
    "    reconstructed = self.decoder(z)\n",
    "    # Add KL divergence regularization loss.\n",
    "    kl_loss = - 0.5 * tf.reduce_mean(\n",
    "        z_log_var - tf.square(z_mean) - tf.exp(z_log_var) + 1)\n",
    "    self.add_loss(kl_loss)\n",
    "    return reconstructed\n",
    "\n",
    "\n",
    "original_dim = 784\n",
    "vae = VariationalAutoEncoder(original_dim, 64, 32)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "mse_loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "loss_metric = tf.keras.metrics.Mean()\n",
    "\n",
    "(x_train, _), _ = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 784).astype('float32') / 255\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(x_train)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "# Iterate over epochs.\n",
    "for epoch in range(3):\n",
    "  print('Start of epoch %d' % (epoch,))\n",
    "\n",
    "  # Iterate over the batches of the dataset.\n",
    "  for step, x_batch_train in enumerate(train_dataset):\n",
    "    with tf.GradientTape() as tape:\n",
    "      reconstructed = vae(x_batch_train)\n",
    "      # Compute reconstruction loss\n",
    "      loss = mse_loss_fn(x_batch_train, reconstructed)\n",
    "      loss += sum(vae.losses)  # Add KLD regularization loss\n",
    "\n",
    "    grads = tape.gradient(loss, vae.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, vae.trainable_weights))\n",
    "\n",
    "    loss_metric(loss)\n",
    "\n",
    "    if step % 100 == 0:\n",
    "      print('step %s: mean loss = %s' % (step, loss_metric.result()))\n",
    "      print('vae losses{}'.format(vae.losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-23T07:13:09.529695Z",
     "start_time": "2019-10-23T07:13:09.525397Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=527266, shape=(), dtype=float32, numpy=0.06794694>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-23T07:13:00.314144Z",
     "start_time": "2019-10-23T07:13:00.309421Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: id=527243, shape=(), dtype=float32, numpy=6.146729e-07>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae.losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
